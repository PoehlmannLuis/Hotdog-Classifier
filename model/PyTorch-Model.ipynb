{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch: package containing multi-dim tensor data structure\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "# torchvision: \n",
    "# package that provides access to popular datasets, model architectures, and image transformations for computer vision\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on the GPU')\n",
    "else:\n",
    "    device = torch.device('cpua') \n",
    "    print('running on the CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 25\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "TRAIN_DATA_PATH = './images/train/'\n",
    "TEST_DATA_PATH = './images/test/'\n",
    "\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, \n",
    "                                             transform=TRANSFORM_IMG)\n",
    "\n",
    "train_loader = data.DataLoader(train_set, \n",
    "                               batch_size=BATCH_SIZE, \n",
    "                               shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, \n",
    "                                            transform=TRANSFORM_IMG)\n",
    "\n",
    "test_loader = data.DataLoader(test_set, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hot_dog': 0, 'not_hot_dog': 1}\n"
     ]
    }
   ],
   "source": [
    "print(test_set.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 'hotdog',\n",
    "             1: 'not hotdog'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\tsail/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=False),\n",
    "    torch.nn.Linear(in_features=1280, out_features=2),\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: 0.676707\n",
      "EPOCH 1: 0.757028\n",
      "EPOCH 2: 0.795181\n",
      "EPOCH 3: 0.827309\n",
      "EPOCH 4: 0.845382\n",
      "EPOCH 5: 0.867470\n",
      "EPOCH 6: 0.853414\n",
      "EPOCH 7: 0.855422\n",
      "EPOCH 8: 0.873494\n",
      "EPOCH 9: 0.879518\n",
      "EPOCH 10: 0.899598\n",
      "EPOCH 11: 0.889558\n",
      "EPOCH 12: 0.907631\n",
      "EPOCH 13: 0.907631\n",
      "EPOCH 14: 0.895582\n",
      "EPOCH 15: 0.907631\n",
      "EPOCH 16: 0.893574\n",
      "EPOCH 17: 0.915663\n",
      "EPOCH 18: 0.907631\n",
      "EPOCH 19: 0.917671\n",
      "EPOCH 20: 0.923695\n",
      "EPOCH 21: 0.917671\n",
      "EPOCH 22: 0.933735\n",
      "EPOCH 23: 0.943775\n",
      "EPOCH 24: 0.927711\n",
      "EPOCH 25: 0.915663\n",
      "EPOCH 26: 0.937751\n",
      "EPOCH 27: 0.931727\n",
      "EPOCH 28: 0.935743\n",
      "EPOCH 29: 0.941767\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "    \n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_set))\n",
    "    print('EPOCH %d: %f' % (epoch, test_accuracy))\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        best_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92.36947791164658 %\n",
      "Correct: 460\n",
      "Total: 498\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))\n",
    "    print('Correct: {}'.format(correct))\n",
    "    print('Total: {}'.format(total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
